{"cells":[{"metadata":{"trusted":true,"_uuid":"2c296b84dbd5447249b6efa2cc46ae87a727e22b"},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport os\nimport seaborn as sns\n%matplotlib inline\nimport random\ndef seed_everything(seed=2020):\n    random.seed(seed)\n    np.random.seed(seed)\nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04d0d84e833e39bdc9fb6f84f9eb26ff9a4aa605"},"cell_type":"code","source":"df = pd.read_csv('../input/plasmaetch/plasmaetch.csv')\ndel df['Unnamed: 0']\nprint(\"Size of the dataframe: \", df.shape); display(df.head(5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ab = df[df['label']==1]\ndf_nnorm = df[df['label']!=1]\n# df_ab.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7a7d7b9019f0f7ca2c430ed3719b938bab9739c"},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nscaler    = MinMaxScaler()\ndf_values = df_ab.drop(['bid'], axis=1)\ncolumn_list = list(df_values.columns) \ndf_values = df_values.drop(['label'], axis=1)\ndf_norm   = scaler.fit_transform(df_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_values.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"01e0a46081857332a650ef2d623c6a380ab82a13"},"cell_type":"markdown","source":"## Training Variational autoencoder (VAE)\n"},{"metadata":{"trusted":true,"_uuid":"30980f33d2580a79b883dad07a5581dad748b18f"},"cell_type":"code","source":"from keras.layers import Lambda, Input, Dense\nfrom keras.models import Model\nfrom keras.losses import mse, binary_crossentropy\nfrom keras.utils import plot_model\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import Input, Dense, Lambda, Layer, Add, Multiply\nfrom keras.models import Model, Sequential\n\nimport argparse\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"664b91c5a4fd3bdbf2fb3e1a273d25d506bbf40f"},"cell_type":"code","source":"# network parameters\noriginal_dim= df_values.shape[1]\ninput_shape = (original_dim, )\nintermediate_dim = int(original_dim/2)\nbatch_size = 128\nlatent_dim = 18\nepochs     = 100\nepsilon_std = 1.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"126c49635d33d00f6d1074157fb047fbabaa5247"},"cell_type":"code","source":"class KLDivergenceLayer(Layer):\n\n    \"\"\" Identity transform layer that adds KL divergence\n    to the final model loss.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        self.is_placeholder = True\n        super(KLDivergenceLayer, self).__init__(*args, **kwargs)\n\n    def call(self, inputs):\n\n        mu, log_var = inputs\n\n        kl_batch = - .5 * K.sum(1 + log_var -\n                                K.square(mu) -\n                                K.exp(log_var), axis=-1)\n\n        self.add_loss(K.mean(kl_batch), inputs=inputs)\n\n        return inputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b455245aa1d5005b841889aec2016af4633a7a33"},"cell_type":"code","source":"# VAE Architecture\n# * original_dim - Original Input Dimension\n# * intermediate_dim - Hidden Layer Dimension\n# * latent_dim - Latent Dimension\nfrom keras.layers.normalization import BatchNormalization\n\ndef vae_arc(original_dim, intermediate_dim, latent_dim):\n    # Encode\n    x = Input(shape=(original_dim,))\n    h = Dense(intermediate_dim, activation='relu')(x)\n    # h = BatchNormalization()(h)\n    # Decode\n    decoder = Sequential([\n        Dense(intermediate_dim, input_dim=latent_dim, activation='relu'),\n        Dense(original_dim, activation='sigmoid')\n    ])\n    z_mu = Dense(latent_dim)(h)\n    z_log_var = Dense(latent_dim)(h)\n\n    z_mu, z_log_var = KLDivergenceLayer()([z_mu, z_log_var])\n    z_sigma = Lambda(lambda t: K.exp(.5*t))(z_log_var)\n\n    eps = Input(tensor=K.random_normal(stddev=epsilon_std,\n                                       shape=(K.shape(x)[0], latent_dim)))\n    z_eps = Multiply()([z_sigma, eps])\n    z = Add()([z_mu, z_eps])\n\n    x_pred = decoder(z)\n    \n    return x, eps, z_mu, x_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4c8625a23a8d51420ad54724a2f41ed0d5f0f06f"},"cell_type":"code","source":"def nll(y_true, y_pred):\n    \"\"\" Negative log likelihood (Bernoulli). \"\"\"\n\n    # keras.losses.binary_crossentropy gives the mean\n    # over the last axis. we require the sum\n    return K.sum(K.binary_crossentropy(y_true, y_pred), axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3304e75a33fc51dc17b95f1e521b0fac6836a8ca"},"cell_type":"code","source":"x, eps, z_mu, x_pred = vae_arc(original_dim, intermediate_dim, latent_dim)\nvae            = Model(inputs=[x, eps], outputs=x_pred)\nvae.compile(optimizer='adam', loss=nll)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bea113ce58a392e385202dcbe9964153d873e534"},"cell_type":"code","source":"vae.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e21818f8561b51cf9abe4ba7508c52413bbb8633"},"cell_type":"markdown","source":"![](https://tiao.io/post/tutorial-on-variational-autoencoders-with-a-concise-keras-implementation/vae_full.svg)"},{"metadata":{"trusted":true,"_uuid":"5b31f3228db81c863893d6d572ffe3566664e503"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# \nX_train, X_test, y_train, y_test = train_test_split(df_norm, df_norm, \n                                                    test_size=0.4, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"221bdb4ebe4b55b4671fd434135e3f3c588ab38d"},"cell_type":"code","source":"filepath   =\"weights.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ef831536f09a40fa9923565f40ea0304dd95073"},"cell_type":"code","source":"# train\nhist = vae.fit(X_train, X_train,\n        epochs=epochs,\n        batch_size=batch_size,\n        callbacks=callbacks_list,\n        validation_data=(X_test, X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"901f0e411d302195ee5daf7a47dda8a31213c618"},"cell_type":"code","source":"def plt_hist(hist):\n    # summarize history for loss\n    plt.plot(hist.history['loss'])\n    plt.plot(hist.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8e73cf84f07f0cea5db6205bb4122ca8f03f2dcb"},"cell_type":"code","source":"plt_hist(hist)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3908b33023a829897368a38cfd81336d34036ec0"},"cell_type":"code","source":"# Predict Embedding values\nencoder = Model(x, z_mu)\nz_df    = encoder.predict(df_norm, batch_size=batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"660a5549c7b4e48bcbb54e633abe21950f3723b2"},"cell_type":"code","source":"df_vae = pd.DataFrame(z_df)\ndf_vae['label'] = 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_vae.columns = column_list\ndf_vae.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nvalues = df.drop(['bid','label'], axis=1)\nscaled_nnorm   = scaler.fit_transform(df_nvalues)\ndf_scaler_nnorm = pd.DataFrame(scaled_nnorm, index=df_nvalues.index, columns=df_nvalues.columns)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_scaler_nnorm['label'] = df.label\n# df_scaler_nnorm.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.concat([df_vae, df_scaler_nnorm], ignore_index=True)\n# df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.drop(['label'], axis=1)\ny = df_train['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import matthews_corrcoef, confusion_matrix,precision_recall_curve,auc,f1_score,roc_auc_score,roc_curve,recall_score,classification_report \nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.cross_validation import KFold, cross_val_score\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef model(algorithm,dtrain_x,dtrain_y,dtest_x,dtest_y):\n    \n    print (\"MODEL - OUTPUT\")\n    print (\"*****************************************************************************************\")\n    algorithm.fit(dtrain_x,dtrain_y)\n    predictions = algorithm.predict(dtest_x)\n    \n    print (algorithm)\n    print (\"\\naccuracy_score :\",accuracy_score(dtest_y,predictions))\n    print (\"\\nrecall score:\\n\",(recall_score(dtest_y,predictions)))\n    print (\"\\nf1 score:\\n\",(f1_score(dtest_y,predictions)))\n#     print (\"\\nclassification report :\\n\",(classification_report(dtest_y,predictions)))\n    print (\"\\nmatthews_corrcoef:\\n\", (matthews_corrcoef(dtest_y, predictions)))\n    #cross validation\n    \n    # Graph\n    plt.figure(figsize=(13,10))\n    plt.subplot(221)\n    sns.heatmap(confusion_matrix(dtest_y,predictions),annot=True,fmt = \"d\",linecolor=\"k\",linewidths=3)\n    plt.title(\"CONFUSION MATRIX\",fontsize=20)\n    \n    predicting_probabilites = algorithm.predict_proba(dtest_x)[:,1]\n    fpr,tpr,thresholds = roc_curve(dtest_y,predicting_probabilites)\n    plt.subplot(222)\n    plt.plot(fpr,tpr,label = (\"Area_under the curve :\",auc(fpr,tpr)),color = \"r\")\n    plt.plot([1,0],[1,0],linestyle = \"dashed\",color =\"k\")\n    plt.legend(loc = \"best\")\n    plt.title(\"ROC - CURVE & AREA UNDER CURVE\",fontsize=20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nclf = DecisionTreeClassifier()\nmodel(clf ,X_train,y_train,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc=SVC(probability=True) \n\nmodel(svc ,X_train,y_train,X_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}